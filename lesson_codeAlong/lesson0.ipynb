{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b92c7e-208e-41ae-9c51-7ca141f1428a",
   "metadata": {},
   "source": [
    "# Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d15b9b9-a1bd-4de7-9319-f9285952de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dea3cc8-7e05-4d4b-80c7-3183207f51e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cbb5bc-f695-45de-8265-a8eb19d6b31d",
   "metadata": {},
   "source": [
    "## Intro to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54896680-20db-49a9-81be-83f440246a52",
   "metadata": {},
   "source": [
    "### Scalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3df2dcf-47ec-4939-afc8-3028d8a81e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575d0b96-7ffe-45a5-960d-03c56a6c242b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81cbb66-d267-452f-b60b-2b1421d44b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returning the values inside the scalar tensor as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f5a48-a7db-4815-abec-ae2b1d37c3aa",
   "metadata": {},
   "source": [
    "### Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e5d2b1-54fc-47ef-96e2-132ee144b4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22f03bf-15b1-4630-a8d6-5de8cac62858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a719a74c-09e1-48e9-a032-6b993d4b109e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Item only works on scalars\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mvector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "#Item only works on scalars\n",
    "vector.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6867394-50d3-43b4-a19d-2549a4953347",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af67461d-26b8-4c96-9cc0-ad3c28568876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2],[3,4]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e6799f-a7ad-41cd-9435-088ae5293d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c35a4-48f8-46c3-ba44-d20e6d9ab072",
   "metadata": {},
   "source": [
    "#### Note: No. of square brackets = ndim value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5cde92-c786-4ca2-8b0e-dfa7e3cb83b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f082fa4-94a7-4963-85fb-08140d856eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a7cac4-7281-4ea9-92f7-6864094bb935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1df19-f355-40bb-a632-782098382a03",
   "metadata": {},
   "source": [
    "### TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f389863-cee2-4aae-9937-48c9f358588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[4, 5],\n",
       "         [6, 7]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1,2],[2,3]],[[4,5],[6,7]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6875c3b6-d252-47fe-b0fb-b1285588344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaaaa4a2-1c92-4916-9001-6c7ff94b7593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 2]), <function Tensor.size>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "596439f7-3e31-4ee7-8aa5-8415d48e2ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192fd93a-2cfa-4215-a629-864f8c483df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "616e313e-01ad-46f3-b665-c079e99ba1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea1513-c29e-4004-98af-85682a47e229",
   "metadata": {},
   "source": [
    "### Random Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25d60f0-013e-4eb4-8a59-cb53d4a9e3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1159, 0.2273, 0.2769, 0.7805],\n",
       "        [0.7323, 0.8736, 0.3058, 0.9558],\n",
       "        [0.5889, 0.4943, 0.3542, 0.9664]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a tensor of specified shape\n",
    "RT = torch.rand(3,4)\n",
    "RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89e39cb0-406e-4bdd-b412-496180bd133c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RT.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ed73212-5877-4755-bdc6-b7efdf2d1b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a tensor of specified image size\n",
    "ImageRT = torch.rand(size=(3,224,224))\n",
    "#224*224 image size with 3 color channels (RGB)\n",
    "ImageRT.shape,ImageRT.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab882a0e-2b30-41b3-adda-8baa0b69e1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
